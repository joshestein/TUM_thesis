{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from monai.utils import set_determinism\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.utils import setup_dirs\n",
    "\n",
    "root_dir = Path(os.getcwd()).parent\n",
    "data_dir, log_dir, out_dir = setup_dirs(root_dir)\n",
    "data_dir = data_dir / \"ACDC\" / \"database\"\n",
    "\n",
    "set_determinism(seed=42)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.transforms.nnunet_transforms import get_nnunet_transforms\n",
    "from src.datasets.acdc_dataset import ACDCDataset\n",
    "from src.sam.sam_utils import get_sam_points\n",
    "\n",
    "train_transforms, val_transforms = get_nnunet_transforms()\n",
    "train_data = ACDCDataset(data_dir=data_dir / \"training\", transform=train_transforms, random_slice=True)\n",
    "test_data = ACDCDataset(\n",
    "    data_dir=data_dir / \"testing\", transform=val_transforms, random_slice=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry\n",
    "\n",
    "model_type = \"vit_h\"\n",
    "checkpoint = root_dir / \"models\" / \"sam_vit_h_4b8939.pth\"\n",
    "sam = sam_model_registry[model_type](checkpoint=checkpoint)\n",
    "sam = sam.to(device)\n",
    "\n",
    "num_classes = 4\n",
    "pos_sample_points = 3\n",
    "neg_sample_points = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_bounding_box(ground_truth_map: np.ndarray, bbox_shift=5) -> np.ndarray:\n",
    "    # get bounding box from mask\n",
    "    y_indices, x_indices = np.where(ground_truth_map > 0)\n",
    "    x_min, x_max = np.min(x_indices), np.max(x_indices)\n",
    "    y_min, y_max = np.min(y_indices), np.max(y_indices)\n",
    "    # add perturbation to bounding box coordinates\n",
    "    H, W = ground_truth_map.shape\n",
    "    x_min = max(0, x_min - bbox_shift)\n",
    "    x_max = min(W, x_max + bbox_shift)\n",
    "    y_min = max(0, y_min - bbox_shift)\n",
    "    y_max = min(H, y_max + bbox_shift)\n",
    "    bboxes = np.array([x_min, y_min, x_max, y_max])\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels == 1]\n",
    "    neg_points = coords[labels == 0]\n",
    "    ax.scatter(\n",
    "        pos_points[:, 0], pos_points[:, 1], color=\"green\", marker=\"*\", s=marker_size, edgecolor=\"white\", linewidth=1.25\n",
    "    )\n",
    "    ax.scatter(\n",
    "        neg_points[:, 0], neg_points[:, 1], color=\"red\", marker=\"*\", s=marker_size, edgecolor=\"white\", linewidth=1.25\n",
    "    )\n",
    "\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor=\"green\", facecolor=(0, 0, 0, 0), lw=2))  # %%\n",
    "\n",
    "\n",
    "def show_figure(num_classes: int, inputs, labels, masks, bboxes, points, point_labels):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        plt.subplot(num_classes, 3, i * 3 + 1)\n",
    "        plt.imshow(inputs, cmap=\"gray\")\n",
    "\n",
    "        if bboxes[i] is not None:\n",
    "            show_box(bboxes[i], plt.gca())\n",
    "\n",
    "        if points[i] is not None:\n",
    "            show_points(points[i], point_labels[i], plt.gca(), marker_size=100)\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(num_classes, 3, i * 3 + 2)\n",
    "        plt.imshow(labels[i])\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(num_classes, 3, i * 3 + 3)\n",
    "        show_mask(masks[i], plt.gca())\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from segment_anything import SamPredictor\n",
    "\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "batch = next(iter(test_loader))\n",
    "inputs, labels = batch[\"image\"][0].to(device), batch[\"label\"][0].to(device, dtype=torch.uint8)\n",
    "\n",
    "# The input to the SAM predictor needs to be HWC, where C = 3 in either RGB or BGR format\n",
    "inputs = cv2.cvtColor(inputs.permute(1, 2, 0).numpy(), cv2.COLOR_GRAY2RGB)\n",
    "# Scale to 0-255, convert to uint8\n",
    "inputs = ((inputs - inputs.min()) * (1 / (inputs.max() - inputs.min()) * 255)).astype(\"uint8\")\n",
    "predictor.set_image(inputs)\n",
    "\n",
    "masks = []\n",
    "labels = labels.cpu().numpy()\n",
    "\n",
    "bboxes = []\n",
    "points, point_labels = (\n",
    "    get_sam_points(labels, num_classes, 5, neg_sample_points)\n",
    ")\n",
    "# Get bounding box for each class of one-hot encoded mask\n",
    "for class_index in range(num_classes):\n",
    "    bbox = get_bounding_box(labels[class_index])\n",
    "    # bbox = None\n",
    "\n",
    "    ground_truth_map, _, _ = predictor.predict(multimask_output=False, box=bbox, point_coords=points[class_index],\n",
    "                                               point_labels=point_labels[class_index])\n",
    "    masks.append(ground_truth_map)\n",
    "    bboxes.append(bbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_figure(num_classes, inputs, labels, masks, bboxes, points, point_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eps = 1e-6\n",
    "dice_scores = []\n",
    "for class_index in range(num_classes):\n",
    "    # Ignore background class\n",
    "    if class_index == 0: continue\n",
    "\n",
    "    ground_truth = (labels == class_index).astype(int)\n",
    "\n",
    "    tp = masks[class_index] * ground_truth\n",
    "    fp = masks[class_index] * (1 - ground_truth)\n",
    "    fn = (1 - masks[class_index]) * ground_truth\n",
    "    tn = (1 - masks[class_index]) * (1 - ground_truth)\n",
    "\n",
    "    dice = (2 * tp.sum() + eps) / (2 * tp.sum() + fp.sum() + fn.sum() + eps)\n",
    "    print(f\"Class {class_index} dice: {dice:.3f}\")\n",
    "    dice_scores.append(dice)\n",
    "\n",
    "print(f\"Average dice: {np.mean(dice_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_image(image, transform, device):\n",
    "    image = cv2.cvtColor(image.permute(1, 2, 0).numpy(), cv2.COLOR_GRAY2RGB)\n",
    "    image = ((image - image.min()) * (1 / (image.max() - image.min()) * 255)).astype(\"uint8\")\n",
    "    image = transform.apply_image(image)\n",
    "    image = torch.as_tensor(image, device=device)\n",
    "    return image.permute(2, 0, 1).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_dice_per_class(masks, labels, ignore_background=True):\n",
    "    dice_scores = []\n",
    "    for class_index, mask in enumerate(masks):\n",
    "        if ignore_background and class_index == 0: continue\n",
    "\n",
    "        ground_truth = (labels == class_index).astype(int)\n",
    "\n",
    "        tp = mask * ground_truth\n",
    "        fp = mask * (1 - ground_truth)\n",
    "        fn = (1 - mask) * ground_truth\n",
    "        # tn = (1 - mask) * (1 - ground_truth)\n",
    "\n",
    "        dice = (2 * tp.sum() + eps) / (2 * tp.sum() + fp.sum() + fn.sum() + eps)\n",
    "        # print(f\"Class {class_index} dice: {dice:.3f}\")\n",
    "        dice_scores.append(dice)\n",
    "\n",
    "    return dice_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "from src.sam.sam_utils import get_batch_predictions\n",
    "\n",
    "resize_transform = ResizeLongestSide(sam.image_encoder.img_size)\n",
    "\n",
    "for batch in test_loader:\n",
    "    inputs, labels, patient = (\n",
    "        batch[\"image\"].to(device),\n",
    "        batch[\"label\"].to(device, dtype=torch.uint8),\n",
    "        batch[\"patient\"],\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        masks, boxes, points, point_labels = get_batch_predictions(\n",
    "            sam=sam,\n",
    "            transform=resize_transform,\n",
    "            inputs=inputs,\n",
    "            labels=labels,\n",
    "            patients=patient,\n",
    "            pos_sample_points=pos_sample_points,\n",
    "            neg_sample_points=neg_sample_points,\n",
    "            num_classes=num_classes,\n",
    "            use_bboxes=True\n",
    "        )\n",
    "        masks = [mask.cpu().numpy() for mask in masks]\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(masks[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_figure(num_classes, inputs[0].permute(1, 2, 0), labels[0], masks[0], boxes[0], points[0], point_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
