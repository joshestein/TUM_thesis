{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import tomllib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import wandb\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet\n",
    "from monai.utils import set_determinism\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from src.metrics import METRICS\n",
    "from src.utils import find_optimal_learning_rate, setup_dirs\n",
    "from src.visualization import visualize_loss_curves, visualize_predictions\n",
    "\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_dir = Path(os.getcwd()).parent\n",
    "data_dir, log_dir, out_dir = setup_dirs(root_dir)\n",
    "data_dir = data_dir / \"ACDC\" / \"database\"\n",
    "\n",
    "with open(root_dir / \"config.toml\", \"rb\") as file:\n",
    "    config = tomllib.load(file)\n",
    "\n",
    "pprint(config)\n",
    "augment = config[\"hyperparameters\"].get(\"augment\", True)\n",
    "batch_size = config[\"hyperparameters\"].get(\"batch_size\", 4)\n",
    "epochs = config[\"hyperparameters\"].get(\"epochs\", 100)\n",
    "learning_rate = config[\"hyperparameters\"].get(\"learning_rate\", 1e-5)\n",
    "percentage_data = config[\"hyperparameters\"].get(\"percentage_data\", 1.0)\n",
    "validation_split = config[\"hyperparameters\"].get(\"validation_split\", 0.8)\n",
    "\n",
    "set_determinism(seed=config[\"hyperparameters\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules[\"src.transforms\"])\n",
    "importlib.reload(sys.modules[\"src.datasets.acdc_dataset\"])\n",
    "from src.transforms.transforms import get_transforms\n",
    "from src.datasets.acdc_dataset import ACDCDataset\n",
    "\n",
    "train_transforms = get_transforms(augment)\n",
    "train_data = ACDCDataset(data_dir=data_dir, train=True, transform=train_transforms)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_dataloader = DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "check_data = next(iter(check_dataloader))\n",
    "image, label = check_data[\"end_diastole\"][0][0], check_data[\"end_diastole_label\"][0][0]\n",
    "\n",
    "print(image.shape, label.shape)\n",
    "\n",
    "# slices = image.shape[2]\n",
    "slices = 1\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(slices, 2), axes_pad=0.1)\n",
    "\n",
    "images = []\n",
    "for i in range(slices):\n",
    "    images.append(image[i, ...])\n",
    "    images.append(label[i, ...])\n",
    "\n",
    "for ax, image in zip(grid, images):\n",
    "    ax.imshow(image, origin=\"lower\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# LV = 3\n",
    "# RV = 1\n",
    "# MYO = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = ACDCDataset(\n",
    "    data_dir=data_dir,\n",
    "    train=True,\n",
    "    transform=train_transforms,\n",
    "    percentage_data=percentage_data,\n",
    ")\n",
    "\n",
    "total_training_number = len(train_data)\n",
    "train_size = int(validation_split * total_training_number)\n",
    "test_size = total_training_number - train_size\n",
    "\n",
    "# TODO: cache dataset\n",
    "# train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=1)\n",
    "# val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=1)\n",
    "\n",
    "train_ds, val_ds = random_split(train_data, [train_size, test_size])\n",
    "print(f\"Training size: {len(train_ds)}\")\n",
    "print(f\"Validation size: {len(val_ds)}\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=4,\n",
    "    # channels=(26, 52, 104, 208, 416),\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    norm=Norm.INSTANCE,\n",
    "    # num_res_units=4,\n",
    "    # dropout=0.5,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.utils import find_optimal_learning_rate\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "# TODO: weight decay check\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Use the config learning rate as a midpoint.\n",
    "optimal_learning_rate = find_optimal_learning_rate(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=loss_function,\n",
    "    device=device,\n",
    "    train_loader=train_loader,\n",
    "    learning_rate=learning_rate,\n",
    "    iterations=100,\n",
    ")\n",
    "\n",
    "for group in optimizer.param_groups:\n",
    "    group[\"lr\"] = optimal_learning_rate\n",
    "\n",
    "config[\"hyperparameters\"][\"optimal_learning_rate\"] = optimal_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"acdc-3D-UNet-baseline\", config=config[\"hyperparameters\"], reinit=True)\n",
    "wandb.config.dataset = \"ACDC\"\n",
    "wandb.config.architecture = \"UNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.train import train\n",
    "\n",
    "val_interval = 5\n",
    "\n",
    "# TODO: if early stopping is desired\n",
    "# early_stopper = EarlyStopper(patience=50, min_delta=10)\n",
    "# Pass as parameter\n",
    "epoch_loss_values, metric_values = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_function=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    val_interval=val_interval,\n",
    "    epochs=epochs,\n",
    "    metrics=metrics,\n",
    "    device=device,\n",
    "    out_dir=out_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_loss_curves(epoch_loss_values, metric_values, val_interval, out_dir)\n",
    "for slice_no in [0, 2, 4]:\n",
    "    visualize_predictions(\n",
    "        model=model,\n",
    "        model_file=os.path.join(out_dir, \"best_metric_model.pth\"),\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        slice_no=slice_no,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "e67800382cf8ea177e3cd7b48d3838fe8a7d931f6b7c8c65c9beb8441d41a67f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
