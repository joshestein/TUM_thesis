{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import tomllib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet\n",
    "from monai.utils import set_determinism\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from src.datasets.acdc_dataset import ACDCDataset\n",
    "from src.transforms import get_transforms\n",
    "from src.utils import find_optimal_learning_rate, setup_dirs\n",
    "from src.visualization import visualize_predictions\n",
    "\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root_dir = Path(os.getcwd()).parent\n",
    "data_dir, log_dir, out_dir = setup_dirs(root_dir)\n",
    "data_dir = data_dir / \"ACDC\" / \"database\"\n",
    "out_dir = out_dir / \"2d_UNet\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "with open(root_dir / \"config.toml\", \"rb\") as file:\n",
    "    config = tomllib.load(file)\n",
    "\n",
    "pprint(config)\n",
    "batch_size = config[\"hyperparameters\"].get(\"epochs\", 1)\n",
    "epochs = config[\"hyperparameters\"].get(\"epochs\", 100)\n",
    "learning_rate = config[\"hyperparameters\"].get(\"learning_rate\", 1e-5)\n",
    "percentage_data = config[\"hyperparameters\"].get(\"percentage_data\", 1.0)\n",
    "validation_split = config[\"hyperparameters\"].get(\"validation_split\", 0.8)\n",
    "\n",
    "set_determinism(seed=config[\"hyperparameters\"][\"seed\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules[\"src.transforms\"])\n",
    "train_transforms = get_transforms()\n",
    "\n",
    "train_data = ACDCDataset(\n",
    "    data_dir=data_dir,\n",
    "    train=True,\n",
    "    transform=train_transforms,\n",
    "    percentage_data=percentage_data,\n",
    ")\n",
    "\n",
    "total_training_number = len(train_data)\n",
    "train_size = int(validation_split * total_training_number)\n",
    "test_size = total_training_number - train_size\n",
    "\n",
    "# TODO: cache dataset\n",
    "# train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=1)\n",
    "# val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=1)\n",
    "\n",
    "train_ds, val_ds = random_split(train_data, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=4,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "\n",
    "# TODO: include_background = False?\n",
    "loss_function = DiceLoss(include_background=False, to_onehot_y=True, softmax=True)\n",
    "# TODO: weight decay check\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "metrics = {\n",
    "    # TODO: include_background = True?\n",
    "    'dice': DiceMetric(include_background=False, reduction=\"mean\"),\n",
    "    'dice_with_background': DiceMetric(include_background=True, reduction=\"mean\"),\n",
    "    'hausdorff': HausdorffDistanceMetric(include_background=False, reduction=\"mean\"),\n",
    "    'dice_per_label': DiceMetric(include_background=False, reduction=\"mean_batch\"),\n",
    "    'dice_per_label_with_background': DiceMetric(include_background=True, reduction=\"mean_batch\"),\n",
    "    'hausdorff_per_label': HausdorffDistanceMetric(include_background=False, reduction=\"mean_batch\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use the config learning rate as a midpoint.\n",
    "optimal_learning_rate = find_optimal_learning_rate(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=loss_function,\n",
    "    device=device,\n",
    "    train_loader=train_loader,\n",
    "    start_lr=learning_rate / 100,\n",
    "    end_lr=learning_rate * 100,\n",
    "    iterations=100,\n",
    ")\n",
    "\n",
    "if optimal_learning_rate is None:\n",
    "    print(\"Optimal learning rate not found, using default learning rate.\")\n",
    "    optimal_learning_rate = learning_rate\n",
    "else:\n",
    "    print(f\"Optimal learning rate found: {optimal_learning_rate}\")\n",
    "\n",
    "for group in optimizer.param_groups:\n",
    "    group[\"lr\"] = optimal_learning_rate\n",
    "\n",
    "config[\"hyperparameters\"][\"optimal_learning_rate\"] = optimal_learning_rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"acdc-2D-UNet-baseline\", config=config[\"hyperparameters\"], reinit=True\n",
    ")\n",
    "wandb.config.dataset = \"ACDC\"\n",
    "wandb.config.architecture = \"2D-UNet\"\n",
    "wandb.config.transforms = train_transforms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.train_2d import train\n",
    "\n",
    "val_interval = 2\n",
    "\n",
    "# TODO: if early stopping is desired\n",
    "# early_stopper = EarlyStopper(patience=50, min_delta=10)\n",
    "# Pass as parameter\n",
    "epoch_loss_values, metric_values = train(model=model, train_loader=train_loader, val_loader=val_loader,\n",
    "                                         loss_function=loss_function, optimizer=optimizer,\n",
    "                                         val_interval=val_interval, epochs=epochs, metrics=metrics, device=device,\n",
    "                                         out_dir=out_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules[\"src.visualization\"])\n",
    "# visualize_loss_curves(epoch_loss_values, metric_values, val_interval, out_dir)\n",
    "for slice_no in [0, 2, 4]:\n",
    "    visualize_predictions(\n",
    "        model=model,\n",
    "        model_file=os.path.join(out_dir, \"best_metric_model.pth\"),\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        slice_no=slice_no,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "e67800382cf8ea177e3cd7b48d3838fe8a7d931f6b7c8c65c9beb8441d41a67f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
