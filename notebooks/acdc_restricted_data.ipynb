{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import tomllib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet\n",
    "from monai.utils import set_determinism\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.datasets.acdc_dataset import ACDCDataset\n",
    "from src.utils import setup_dirs\n",
    "from src.visualization import visualize_loss_curves, visualize_predictions\n",
    "\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(os.getcwd()).parent\n",
    "data_dir, log_dir, root_out_dir = setup_dirs(root_dir)\n",
    "data_dir = data_dir / \"ACDC\" / \"database\"\n",
    "\n",
    "with open(root_dir / \"config.toml\", \"rb\") as file:\n",
    "    config = tomllib.load(file)\n",
    "\n",
    "pprint(config)\n",
    "batch_size = config[\"hyperparameters\"].get(\"batch_size\", 4)\n",
    "epochs = config[\"hyperparameters\"].get(\"epochs\", 100)\n",
    "learning_rate = config[\"hyperparameters\"].get(\"learning_rate\", 1e-5)\n",
    "percentage_data = config[\"hyperparameters\"].get(\"percentage_data\", 1.0)\n",
    "validation_split = config[\"hyperparameters\"].get(\"validation_split\", 0.8)\n",
    "\n",
    "set_determinism(seed=config[\"hyperparameters\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from src.transforms.transforms import get_transforms\n",
    "\n",
    "importlib.reload(sys.modules[\"src.transforms\"])\n",
    "\n",
    "augment = True\n",
    "config[\"hyperparameters\"][\"augmentations\"] = augment\n",
    "train_transforms, val_transforms = get_transforms(augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=4,\n",
    "    # channels=(26, 52, 104, 208, 416),\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    norm=Norm.BATCH,\n",
    "    # num_res_units=4,\n",
    "    # dropout=0.5,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "# TODO: weight decay check\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_loader = DataLoader(\n",
    "    ACDCDataset(data_dir=data_dir / \"training\", transform=train_transforms),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Find the optimal learning rate using the full dataset\n",
    "# Use the config learning rate as a midpoint.\n",
    "# optimal_learning_rate = find_optimal_learning_rate(\n",
    "#     model=model,\n",
    "#     optimizer=optimizer,\n",
    "#     criterion=loss_function,\n",
    "#     device=device,\n",
    "#     train_loader=full_dataset_loader,\n",
    "#     start_lr=learning_rate / 1000,\n",
    "#     end_lr=learning_rate * 1000,\n",
    "#     iterations=epochs,\n",
    "# )\n",
    "\n",
    "optimal_learning_rate = 0.00039565388658322663\n",
    "if optimal_learning_rate is None:\n",
    "    print(\"Optimal learning rate not found, using default learning rate.\")\n",
    "    optimal_learning_rate = learning_rate\n",
    "else:\n",
    "    print(f\"Optimal learning rate found: {optimal_learning_rate}\")\n",
    "\n",
    "for group in optimizer.param_groups:\n",
    "    group[\"lr\"] = optimal_learning_rate\n",
    "\n",
    "config[\"hyperparameters\"][\"optimal_learning_rate\"] = optimal_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from src.utils import get_datasets, get_train_dataloaders\n",
    "\n",
    "importlib.reload(sys.modules[\"src.train\"])\n",
    "importlib.reload(sys.modules[\"src.datasets.acdc_dataset\"])\n",
    "from src.train import train\n",
    "from src.datasets.acdc_dataset import ACDCDataset\n",
    "import gc\n",
    "\n",
    "val_interval = 5\n",
    "\n",
    "percentage_data = 1.0\n",
    "config[\"hyperparameters\"][\"percentage_data\"] = percentage_data\n",
    "\n",
    "for percentage_slices in [0.1, 0.05]:\n",
    "    config[\"hyperparameters\"][\"percentage_slices\"] = percentage_slices\n",
    "\n",
    "    train_data = ACDCDataset(\n",
    "        data_dir=data_dir / \"training\",\n",
    "        transform=train_transforms,\n",
    "        percentage_data=percentage_data,\n",
    "    )\n",
    "\n",
    "    # Re-initialize model\n",
    "    model = UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=4,\n",
    "        # channels=(26, 52, 104, 208, 416),\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        norm=Norm.BATCH,\n",
    "        # num_res_units=4,\n",
    "        # dropout=0.5,\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=optimal_learning_rate)\n",
    "\n",
    "    print(f\"Number of training samples: {len(train_data)}\")\n",
    "    train_data, val_data = get_datasets(\n",
    "        augment=augment,\n",
    "        percentage_data=percentage_data,\n",
    "        percentage_slices=percentage_slices,\n",
    "        data_dir=data_dir / \"training\",\n",
    "    )\n",
    "\n",
    "    train_loader, val_loader = get_train_dataloaders(\n",
    "        train_dataset=train_data,\n",
    "        val_dataset=val_data,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "    )\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"acdc-3D-UNet-baseline-restart\", config=config[\"hyperparameters\"], tags=[\"limited_slices\"],\n",
    "        dir=log_dir,\n",
    "        reinit=True,\n",
    "    )\n",
    "    wandb.config.dataset = \"ACDC\"\n",
    "    wandb.config.architecture = \"UNet\"\n",
    "\n",
    "    out_dir = root_out_dir / f\"percentage_data_{percentage_data}\" / f\"percentage_slices_{percentage_slices}\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    epoch_loss_values, metric_values = train(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        loss_function=loss_function,\n",
    "        optimizer=optimizer,\n",
    "        val_interval=val_interval,\n",
    "        epochs=epochs,\n",
    "        device=device,\n",
    "        out_dir=out_dir,\n",
    "        dimensions=3\n",
    "    )\n",
    "\n",
    "    wandb.finish()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # model.load_state_dict(state_cacher.retrieve(\"model\"))\n",
    "    # model.to(device)\n",
    "\n",
    "    # visualize_loss_curves(epoch_loss_values, metric_values, val_interval, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_loss_curves(epoch_loss_values, metric_values, val_interval, out_dir)\n",
    "for slice_no in [0, 2, 4]:\n",
    "    visualize_predictions(\n",
    "        model=model,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        slice_no=slice_no,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "e67800382cf8ea177e3cd7b48d3838fe8a7d931f6b7c8c65c9beb8441d41a67f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
