{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import tomllib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet\n",
    "from monai.utils import set_determinism\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from src.datasets.acdc_dataset import ACDCDataset\n",
    "from src.train import train\n",
    "from src.transforms import get_transforms\n",
    "from src.utils import find_optimal_learning_rate, setup_dirs\n",
    "from src.visualization import visualize_loss_curves, visualize_predictions\n",
    "\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root_dir = Path(os.getcwd()).parent\n",
    "data_dir, log_dir, root_out_dir = setup_dirs(root_dir)\n",
    "data_dir = data_dir / \"ACDC\" / \"database\"\n",
    "\n",
    "with open(root_dir / \"config.toml\", \"rb\") as file:\n",
    "    config = tomllib.load(file)\n",
    "\n",
    "pprint(config)\n",
    "batch_size = config[\"hyperparameters\"].get(\"batch_size\", 4)\n",
    "epochs = config[\"hyperparameters\"].get(\"epochs\", 100)\n",
    "learning_rate = config[\"hyperparameters\"].get(\"learning_rate\", 1e-5)\n",
    "percentage_data = config[\"hyperparameters\"].get(\"percentage_data\", 1.0)\n",
    "validation_split = config[\"hyperparameters\"].get(\"validation_split\", 0.8)\n",
    "\n",
    "set_determinism(seed=config[\"hyperparameters\"][\"seed\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules[\"src.transforms\"])\n",
    "\n",
    "train_transforms = get_transforms()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=4,\n",
    "    # channels=(26, 52, 104, 208, 416),\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    norm=Norm.BATCH,\n",
    "    # num_res_units=4,\n",
    "    # dropout=0.5,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "# TODO: weight decay check\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "metrics = {\n",
    "    \"dice\": DiceMetric(include_background=False, reduction=\"mean\"),\n",
    "    \"dice_with_background\": DiceMetric(include_background=True, reduction=\"mean\"),\n",
    "    \"hausdorff\": HausdorffDistanceMetric(include_background=False, reduction=\"mean\"),\n",
    "    \"dice_per_label\": DiceMetric(include_background=False, reduction=\"mean_batch\"),\n",
    "    \"dice_per_label_with_background\": DiceMetric(include_background=True, reduction=\"mean_batch\"),\n",
    "    \"hausdorff_per_label\": HausdorffDistanceMetric(include_background=False, reduction=\"mean_batch\"),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_dataset_loader = DataLoader(\n",
    "    ACDCDataset(\n",
    "        data_dir=data_dir, train=True, transform=train_transforms, percentage_data=1\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "# Find the optimal learning rate using the full dataset\n",
    "# Use the config learning rate as a midpoint.\n",
    "optimal_learning_rate = find_optimal_learning_rate(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=loss_function,\n",
    "    device=device,\n",
    "    train_loader=full_dataset_loader,\n",
    "    start_lr=learning_rate / 100,\n",
    "    end_lr=learning_rate * 100,\n",
    "    iterations=100,\n",
    ")\n",
    "\n",
    "if optimal_learning_rate is None:\n",
    "    print(\"Optimal learning rate not found, using default learning rate.\")\n",
    "    optimal_learning_rate = learning_rate\n",
    "else:\n",
    "    print(f\"Optimal learning rate found: {optimal_learning_rate}\")\n",
    "\n",
    "for group in optimizer.param_groups:\n",
    "    group[\"lr\"] = optimal_learning_rate\n",
    "\n",
    "config[\"hyperparameters\"][\"optimal_learning_rate\"] = optimal_learning_rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_train_dataloaders(dataset: torch.utils.data.Dataset):\n",
    "    total_training_number = len(dataset)\n",
    "    train_size = int(validation_split * total_training_number)\n",
    "    test_size = total_training_number - train_size\n",
    "\n",
    "    train_ds, val_ds = random_split(dataset, [train_size, test_size])\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, shuffle=True, num_workers=1\n",
    "    )\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "    return train_loader, val_loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_interval = 5\n",
    "\n",
    "for percentage_data in [0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "    for percentage_slices in [0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "        config[\"hyperparameters\"][\"percentage_data\"] = percentage_data\n",
    "        config[\"hyperparameters\"][\"percentage_slices\"] = percentage_slices\n",
    "\n",
    "        train_data = ACDCDataset(\n",
    "            data_dir=data_dir,\n",
    "            train=True,\n",
    "            transform=train_transforms,\n",
    "            percentage_data=percentage_data,\n",
    "        )\n",
    "\n",
    "        train_loader, val_loader = get_train_dataloaders(train_data)\n",
    "\n",
    "        # Re-initialize model\n",
    "        model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=4,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            norm=Norm.BATCH,\n",
    "        ).to(device)\n",
    "\n",
    "        wandb.init(\n",
    "            project=\"acdc-3D-UNet-baseline\", config=config[\"hyperparameters\"], tags=[\"limited_data\"], dir=log_dir,\n",
    "            reinit=True\n",
    "        )\n",
    "        wandb.config.dataset = \"ACDC\"\n",
    "        wandb.config.architecture = \"UNet\"\n",
    "\n",
    "        out_dir = root_out_dir / f\"percentage_data_{percentage_data}\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        epoch_loss_values, metric_values = train(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            loss_function=loss_function,\n",
    "            optimizer=optimizer,\n",
    "            val_interval=val_interval,\n",
    "            epochs=epochs,\n",
    "            metrics=metrics,\n",
    "            device=device,\n",
    "            out_dir=out_dir,\n",
    "        )\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "        # visualize_loss_curves(epoch_loss_values, metric_values, val_interval, out_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_loss</td><td>█▇▆▅▆▆▆▅▅▆▅▄▄▄▄▄▄▃▄▂▃▃▄▄▃▃▂▂▃▂▂▃▁▂▃▃▃▄▁▂</td></tr><tr><td>validation_dice</td><td>▁▆▅▅▅▁▄▇▆▃▅▄▅▅█▆</td></tr><tr><td>validation_dice_with_background</td><td>▁▆▅▅▅▁▄▇▆▃▅▄▅▅█▆</td></tr><tr><td>validation_hausdorff</td><td>▂▂▅▄▂▃▃▂▂▃▃▃▁▁█▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_loss</td><td>0.08908</td></tr><tr><td>validation_dice</td><td>0.71847</td></tr><tr><td>validation_dice_with_background</td><td>0.78625</td></tr><tr><td>validation_hausdorff</td><td>18.70666</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/josh-stein/acdc-3D-UNet-baseline' target=\"_blank\">https://wandb.ai/josh-stein/acdc-3D-UNet-baseline</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>/Users/joshstein/Documents/thesis/code/logs/wandb/run-20230324_140851-rdsydeji/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_loss_curves(epoch_loss_values, metric_values, val_interval, out_dir)\n",
    "for slice_no in [0, 2, 4]:\n",
    "    visualize_predictions(\n",
    "        model=model,\n",
    "        model_file=os.path.join(out_dir, \"best_metric_model.pth\"),\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        image_key=\"end_diastole\",\n",
    "        label_key=\"end_diastole_label\",\n",
    "        slice_no=slice_no,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "e67800382cf8ea177e3cd7b48d3838fe8a7d931f6b7c8c65c9beb8441d41a67f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
