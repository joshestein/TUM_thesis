{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import tomllib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet\n",
    "from monai.utils import set_determinism\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from src.datasets.acdc_dataset import ACDCDataset\n",
    "from src.train import train\n",
    "from src.transforms import get_transforms\n",
    "from src.utils import find_optimal_learning_rate, setup_dirs\n",
    "from src.visualization import visualize_loss_curves, visualize_predictions\n",
    "\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root_dir = Path(os.getcwd()).parent\n",
    "data_dir, log_dir, root_out_dir = setup_dirs(root_dir)\n",
    "data_dir = data_dir / \"ACDC\" / \"database\"\n",
    "\n",
    "with open(root_dir / \"config.toml\", \"rb\") as file:\n",
    "    config = tomllib.load(file)\n",
    "\n",
    "pprint(config)\n",
    "batch_size = config[\"hyperparameters\"].get(\"batch_size\", 4)\n",
    "epochs = config[\"hyperparameters\"].get(\"epochs\", 100)\n",
    "learning_rate = config[\"hyperparameters\"].get(\"learning_rate\", 1e-5)\n",
    "percentage_data = config[\"hyperparameters\"].get(\"percentage_data\", 1.0)\n",
    "validation_split = config[\"hyperparameters\"].get(\"validation_split\", 0.8)\n",
    "\n",
    "set_determinism(seed=config[\"hyperparameters\"][\"seed\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(sys.modules[\"src.transforms\"])\n",
    "\n",
    "train_transforms = get_transforms()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=4,\n",
    "    # channels=(26, 52, 104, 208, 416),\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    norm=Norm.BATCH,\n",
    "    # num_res_units=4,\n",
    "    # dropout=0.5,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "# TODO: weight decay check\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "metrics = {\n",
    "    \"dice\": DiceMetric(include_background=False, reduction=\"mean\"),\n",
    "    \"dice_with_background\": DiceMetric(include_background=True, reduction=\"mean\"),\n",
    "    \"hausdorff\": HausdorffDistanceMetric(include_background=False, reduction=\"mean\"),\n",
    "    \"dice_per_label\": DiceMetric(include_background=False, reduction=\"mean_batch\"),\n",
    "    \"dice_per_label_with_background\": DiceMetric(include_background=True, reduction=\"mean_batch\"),\n",
    "    \"hausdorff_per_label\": HausdorffDistanceMetric(include_background=False, reduction=\"mean_batch\"),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_dataset_loader = DataLoader(\n",
    "    ACDCDataset(\n",
    "        data_dir=data_dir, train=True, transform=train_transforms, percentage_data=1\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "# Find the optimal learning rate using the full dataset\n",
    "# Use the config learning rate as a midpoint.\n",
    "optimal_learning_rate = find_optimal_learning_rate(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=loss_function,\n",
    "    device=device,\n",
    "    train_loader=full_dataset_loader,\n",
    "    start_lr=learning_rate / 100,\n",
    "    end_lr=learning_rate * 100,\n",
    "    iterations=100,\n",
    ")\n",
    "\n",
    "if optimal_learning_rate is None:\n",
    "    print(\"Optimal learning rate not found, using default learning rate.\")\n",
    "    optimal_learning_rate = learning_rate\n",
    "else:\n",
    "    print(f\"Optimal learning rate found: {optimal_learning_rate}\")\n",
    "\n",
    "for group in optimizer.param_groups:\n",
    "    group[\"lr\"] = optimal_learning_rate\n",
    "\n",
    "config[\"hyperparameters\"][\"optimal_learning_rate\"] = optimal_learning_rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_train_dataloaders(dataset: torch.utils.data.Dataset):\n",
    "    total_training_number = len(dataset)\n",
    "    train_size = int(validation_split * total_training_number)\n",
    "    test_size = total_training_number - train_size\n",
    "\n",
    "    train_ds, val_ds = random_split(dataset, [train_size, test_size])\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, shuffle=True, num_workers=1\n",
    "    )\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "    return train_loader, val_loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mjosh-stein\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01669572708196938, max=1.0)â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0896c7b2f7cd483e8f66af897afb6278"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.14.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.13.10"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/joshstein/Documents/thesis/code/logs/wandb/run-20230324_114103-loia50mw</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/josh-stein/acdc-3D-UNet-baseline/runs/loia50mw' target=\"_blank\">dazzling-shape-37</a></strong> to <a href='https://wandb.ai/josh-stein/acdc-3D-UNet-baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/josh-stein/acdc-3D-UNet-baseline' target=\"_blank\">https://wandb.ai/josh-stein/acdc-3D-UNet-baseline</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>/Users/joshstein/Documents/thesis/code/logs/wandb/run-20230324_140851-rdsydeji/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_loss_curves(epoch_loss_values, metric_values, val_interval, out_dir)\n",
    "for slice_no in [0, 2, 4]:\n",
    "    visualize_predictions(\n",
    "        model=model,\n",
    "        model_file=os.path.join(out_dir, \"best_metric_model.pth\"),\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        image_key=\"end_diastole\",\n",
    "        label_key=\"end_diastole_label\",\n",
    "        slice_no=slice_no,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "e67800382cf8ea177e3cd7b48d3838fe8a7d931f6b7c8c65c9beb8441d41a67f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
